<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pr√°ctica de Destilaci√≥n de Modelos - ASIR</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
            line-height: 1.6;
        }
        
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.2);
            overflow: hidden;
        }
        
        header {
            background: linear-gradient(135deg, #2c3e50 0%, #34495e 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }
        
        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }
        
        header p {
            font-size: 1.2em;
            opacity: 0.9;
        }
        
        .content {
            padding: 40px;
        }
        
        .section {
            margin-bottom: 50px;
            background: #f8f9fa;
            border-radius: 10px;
            padding: 30px;
            box-shadow: 0 3px 10px rgba(0,0,0,0.1);
        }
        
        .section h2 {
            color: #2c3e50;
            font-size: 1.8em;
            margin-bottom: 20px;
            padding-bottom: 10px;
            border-bottom: 3px solid #667eea;
        }
        
        .explanation {
            background: white;
            padding: 20px;
            border-radius: 8px;
            margin-bottom: 20px;
            border-left: 4px solid #667eea;
        }
        
        .explanation p {
            color: #34495e;
            font-size: 1.05em;
            margin-bottom: 10px;
        }
        
        .explanation ul {
            margin-left: 25px;
            color: #555;
        }
        
        .explanation li {
            margin-bottom: 8px;
        }
        
        .image-container {
            text-align: center;
            background: #2c3e50;
            padding: 20px;
            border-radius: 8px;
            margin-top: 20px;
        }
        
        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
            box-shadow: 0 5px 15px rgba(0,0,0,0.3);
        }
        
        .badge {
            display: inline-block;
            background: #667eea;
            color: white;
            padding: 5px 15px;
            border-radius: 20px;
            font-size: 0.9em;
            margin-bottom: 15px;
        }
        
        footer {
            background: #2c3e50;
            color: white;
            text-align: center;
            padding: 20px;
            font-size: 0.9em;
        }
        
        .highlight {
            background: #fff3cd;
            padding: 2px 6px;
            border-radius: 3px;
            font-weight: bold;
        }
        
        .code-block {
            background: #1e1e1e;
            color: #d4d4d4;
            padding: 15px;
            border-radius: 5px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            overflow-x: auto;
            margin: 10px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>üß™ Pr√°ctica de Destilaci√≥n de Modelos</h1>
            <p>Knowledge Distillation con Qwen2.5 y Python</p>
        </header>
        
        <div class="content">
            <!-- Secci√≥n 1: Imagen 1 (con teor√≠a de imagen 2) -->
            <div class="section">
                <span class="badge">Captura 1</span>
                <h2>Instalaci√≥n de Dependencias del Proyecto</h2>
                
                <div class="explanation">
                    <p><strong>üìù Descripci√≥n:</strong></p>
                    <p>Se ejecuta el comando <code>pip install torch transformers accelerate</code> para instalar las bibliotecas necesarias para el proceso de destilaci√≥n de modelos.</p>
                    
                    <p><strong>üì¶ Paquetes principales instalados:</strong></p>
                    <ul>
                        <li><strong>torch (PyTorch) 2.1.0:</strong> Framework de deep learning para operaciones tensoriales y redes neuronales (optimizado para macOS ARM64)</li>
                        <li><strong>transformers 5.1.0:</strong> Biblioteca de Hugging Face para trabajar con modelos transformer (BERT, GPT, Qwen, etc.)</li>
                        <li><strong>accelerate 1.2.0:</strong> Simplifica el entrenamiento en m√∫ltiples GPUs y entornos distribuidos</li>
                    </ul>
                    
                    <p><strong>üîß Dependencias adicionales:</strong></p>
                    <ul>
                        <li>filelock, typing_extensions, sympy, networkx, jinja2</li>
                    </ul>
                    
                    <p><strong>‚úÖ Resultado:</strong> Instalaci√≥n exitosa usando archivos en cach√© local. El entorno est√° listo para ejecutar scripts de destilaci√≥n.</p>
                </div>
                
                <div class="image-container">
                    <img src="Imagen1Destilacion.png" alt="Imagen 1 - Instalaci√≥n de dependencias">
                </div>
            </div>
            
            <!-- Secci√≥n 2: Imagen 2 (con teor√≠a de imagen 1) -->
            <div class="section">
                <span class="badge">Captura 2</span>
                <h2>Ejecuci√≥n del Script y Carga de Modelos</h2>
                
                <div class="explanation">
                    <p><strong>üìù Descripci√≥n:</strong></p>
                    <p>Se ejecuta el script <code>medir_kl.py</code> desde la terminal en entorno virtual (venv). El sistema utiliza MPS (Metal Performance Shaders) para aceleraci√≥n GPU en macOS.</p>
                    
                    <p><strong>üîç Proceso de carga:</strong></p>
                    <ul>
                        <li><strong>Fase 1 - Tokenizador:</strong> 
                            <ul style="margin-top: 5px;">
                                <li>config.json (662 bytes), vocab.json (2.7MB), merges.txt (1.4MB), tokenizer.json (7.0MB)</li>
                            </ul>
                        </li>
                        <li><strong>Fase 2 - Modelo Profesor:</strong> 
                            <ul style="margin-top: 5px;">
                                <li>Qwen/Qwen2.5-0.5B - model.safetensors (~494MB, 291/291 archivos)</li>
                            </ul>
                        </li>
                        <li><strong>Fase 3 - Modelo Estudiante:</strong> 
                            <ul style="margin-top: 5px;">
                                <li>Mismo modelo cargado para comparaci√≥n (643/661 y 291/291 archivos)</li>
                            </ul>
                        </li>
                    </ul>
                    
                    <p><strong>‚ö° Resultado:</strong> <span class="highlight">DIVERGENCIA KL: 1.706555</span></p>
                    <p>Este valor mide la diferencia entre las distribuciones de probabilidad del profesor y estudiante. Durante la destilaci√≥n, este valor debe reducirse.</p>
                </div>
                
                <div class="image-container">
                    <img src="Imagen2Destilacion.png" alt="Imagen 2 - Ejecuci√≥n y carga de modelos">
                </div>
            </div>
            
            <!-- Secci√≥n 3: Imagen 3 -->
            <div class="section">
                <span class="badge">Captura 3</span>
                <h2>Comparaci√≥n de Predicciones Top-10</h2>
                
                <div class="explanation">
                    <p><strong>üìù Descripci√≥n:</strong></p>
                    <p>Comparaci√≥n de predicciones entre profesor y estudiante para el prompt <em>"La inteligencia artificial es"</em>.</p>
                    
                    <p><strong>üìä Predicciones del Profesor:</strong></p>
                    <ul>
                        <li>1. "un" (30.0%) - 2. "una" (29.7%) - 3. "la" (7.5%) - 4. "una" (5.3%) - 5. "el" (3.3%)</li>
                        <li>Los dos primeros tokens acumulan ~60% de probabilidad (alta confianza)</li>
                    </ul>
                    
                    <p><strong>üéì Predicciones del Estudiante:</strong></p>
                    <ul>
                        <li>1. "una" (8.2%) - 2. "la" (2.3%) - 3. "un" (1.7%) - 4. "el" (1.1%) - 5. "una" (0.7%)</li>
                        <li>Distribuci√≥n m√°s uniforme y menos confiada (m√°ximo 8.2%)</li>
                        <li>Incluye token inesperado: "cama" (1.3%)</li>
                    </ul>
                    
                    <p><strong>üîç An√°lisis:</strong></p>
                    <p>El profesor muestra predicciones m√°s confiadas mientras el estudiante tiene distribuciones dispersas. El orden de preferencia tambi√©n difiere. <span class="highlight">KL Divergencia: 1.706555</span> indica que el estudiante debe mejorar para imitar al profesor.</p>
                </div>
                
                <div class="image-container">
                    <img src="Imagen3Destilacion.png" alt="Imagen 3 - Comparaci√≥n de predicciones">
                </div>
            </div>
            
            <!-- Secci√≥n 4: Imagen 4 -->
            <div class="section">
                <span class="badge">Captura 4</span>
                <h2>Benchmark LAMBADA y Advertencias</h2>
                
                <div class="explanation">
                    <p><strong>üìù Descripci√≥n:</strong></p>
                    <p>Ejecuci√≥n del script <code>preguntas_dificiles_prof_para_conneccion.py</code> para configurar el benchmark LAMBADA (Language Modeling Broadened to Account for Discourse Aspects).</p>
                    
                    <p><strong>‚ö†Ô∏è Advertencia detectada:</strong></p>
                    <div class="code-block">
The following generation flags are not valid and may be ignored: ['temperature'].
Set `TRANSFORMERS_VERBOSITY=info` for more details.
                    </div>
                    
                    <p><strong>üîß An√°lisis:</strong></p>
                    <ul>
                        <li>El par√°metro 'temperature' no est√° soportado en el modo actual y ser√° ignorado</li>
                        <li>Otros flags: {'rep': 'repetition'}, {'leng': 'length'}, {'freq': 'frequency'}</li>
                    </ul>
                    
                    <p><strong>üìä Configuraci√≥n LAMBADA:</strong></p>
                    <ul>
                        <li><strong>Prop√≥sito:</strong> Evaluar comprensi√≥n contextual prediciendo la √∫ltima palabra de textos largos</li>
                        <li><strong>Modo:</strong> BENCHMARK ESTRICTO - Solo respuestas TOPK</li>
                        <li><strong>Evaluaci√≥n:</strong> PROFESOR DOMINA - el profesor gu√≠a la evaluaci√≥n</li>
                    </ul>
                    
                    <p><strong>üí° Soluci√≥n:</strong> Ejecutar <code>export TRANSFORMERS_VERBOSITY=info</code> o modificar el c√≥digo para eliminar el par√°metro 'temperature'.</p>
                </div>
                
                <div class="image-container">
                    <img src="Imagen4Destilacion.png" alt="Imagen 4 - Benchmark LAMBADA">
                </div>
            </div>
            
        </div>
        
        <footer>
            <p><strong>Pr√°ctica de Destilaci√≥n de Modelos - ASIR</strong></p>
            <p>Febrero 2026 | Knowledge Distillation con Qwen2.5</p>
        </footer>
    </div>
</body>
</html>
