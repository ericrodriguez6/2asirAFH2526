<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>Fine-tuning de Gemma 3-270M-it con MLX-LM-LoRA</title>
  <style>
    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
      margin: 0;
      padding: 2rem;
      background-color: #0b1020;
      color: #f4f4f4;
    }
    h1, h2 {
      text-align: center;
    }
    .step {
      border: 1px solid #444;
      border-radius: 8px;
      padding: 1rem 1.5rem;
      margin: 1.5rem auto;
      max-width: 960px;
      background: #151a2a;
      box-shadow: 0 2px 8px rgba(0,0,0,0.4);
    }
    .step h2 {
      margin-top: 0;
      font-size: 1.2rem;
      color: #ffe28a;
    }
    .step p {
      line-height: 1.5;
    }
    .step img {
      display: block;
      max-width: 100%;
      height: auto;
      margin: 0.75rem auto;
      border-radius: 6px;
      border: 1px solid #333;
    }
    .caption {
      font-size: 0.9rem;
      color: #c7c7c7;
      text-align: center;
      margin-top: 0.25rem;
    }
    .small-note {
      font-size: 0.8rem;
      text-align: center;
      color: #aaaaaa;
    }
  </style>
</head>
<body>

  <h1>Memoria de Fine-tuning<br>Gemma 3‑270M‑it con MLX‑LM‑LoRA</h1>
  <p class="small-note">
    Secuencia de pasos desde la creación del entorno hasta el entrenamiento exitoso del modelo.
  </p>

  <!-- Paso 1 -->
  <section class="step">
    <h2>Paso 1 – Creación del entorno e instalación de dependencias</h2>
    <p>
      En este primer paso creo el directorio de>gemma-finetune-v2</code>, 
      genero y activo el entorno virtual de Python y actualizo de>pip</code>. 
      A continuación instalo los paquetes necesarios (de>mlx-lm</code>, 
      de>datasets</code>, de>huggingface_hub</code>, de>accelerate</code>).
    </p>
    <!-- GitHub File: WhatsApp Image 2026-02-06 at 16.28.38.jpeg -->
    <img src="WhatsApp%20Image%202026-02-06%20at%2016.28.38.jpeg" alt="Instalación de entorno y dependencias">
    <div class="caption">Instalación del entorno virtual y de las librerías necesarias para MLX‑LM.</div>
  </section>

  <!-- Paso 2 -->
  <section class="step">
    <h2>Paso 2 – Autenticación en Hugging Face</h2>
    <p>
      Configuro el acceso a Hugging Face ejecutando de>huggingface-cli login</code>. 
      Introduzco el token personal para poder descargar el modelo base Gemma.
    </p>
    <!-- GitHub File: WhatsApp Image 2026-02-06 at 16.28.39 (3).jpeg -->
    <img src="WhatsApp%20Image%202026-02-06%20at%2016.28.39%20(3).jpeg" alt="Login en Hugging Face">
    <div class="caption">Proceso de login en Hugging Face desde la terminal.</div>
  </section>

  <!-- Paso 3 -->
  <section class="step">
    <h2>Paso 3 – Primeros ficheros de datos en JSONL</h2>
    <p>
      Creo el directorio de>data/</code> y genero de>train.jsonl</code> y 
      de>valid.jsonl</code>. Uso de>head</code> para comprobar el contenido, 
      aunque aparece un error al interpretar el comentario de># Verifica</code>.
    </p>
    <!-- GitHub File: WhatsApp Image 2026-02-06 at 16.28.40 (3).jpeg -->
    <img src="WhatsApp%20Image%202026-02-06%20at%2016.28.40%20(3).jpeg" alt="Creación inicial de train y valid JSONL">
    <div class="caption">Generación manual de los primeros ficheros de>train.jsonl</code> y de>valid.jsonl</code>.</div>
  </section>

  <!-- Paso 4 -->
  <section class="step">
    <h2>Paso 4 – Intento de lanzar el comando de LoRA</h2>
    <p>
      Intento iniciar el entrenamiento con de>mlx_lm.lora</code>, pero el shell devuelve 
      de>command not found</code>. El ejecutable correcto es de>mlx_lm_lora.train</code>.
    </p>
    <!-- GitHub File: WhatsApp Image 2026-02-06 at 16.28.40 (2).jpeg -->
    <img src="WhatsApp%20Image%202026-02-06%20at%2016.28.40%20(2).jpeg" alt="Comando mlx_lm.lora no encontrado">
    <div class="caption">Primer intento fallido de lanzar el entrenamiento con el comando incorrecto.</div>
  </section>

  <!-- Paso 5 -->
  <section class="step">
    <h2>Paso 5 – Creación de un archivo de configuración YAML</h2>
    <p>
      Preparo un fichero de>train.yaml</code> para simplificar los parámetros. 
      Al ejecutar con de>--config</code> sigue sin encontrar el comando, confirmando 
      que debo usar la interfaz de>mlx_lm_lora.train</code>.
    </p>
    <!-- GitHub File: WhatsApp Image 2026-02-06 at 16.28.40 (1).jpeg -->
    <img src="WhatsApp%20Image%202026-02-06%20at%2016.28.40%20(1).jpeg" alt="Creación de train.yaml">
    <div class="caption">Definición de la configuración de entrenamiento en formato YAML.</div>
  </section>

  <!-- Paso 6 -->
  <section class="step">
    <h2>Paso 6 – Primer entrenamiento: error por tamaño de dataset</h2>
    <p>
      Lanzo el entrenamiento con de>mlx_lm_lora.train</code>. Aparece el error 
      de>ValueError: Dataset must have at least batch_size*2 examples</code>.
    </p>
    <!-- GitHub File: WhatsApp Image 2026-02-06 at 16.28.39 (2).jpeg -->
    <img src="WhatsApp%20Image%202026-02-06%20at%2016.28.39%20(2).jpeg" alt="Error de dataset vs batch_size">
    <div class="caption">El entrenamiento se detiene porque el conjunto de validación es muy pequeño.</div>
  </section>

  <!-- Paso 7 -->
  <section class="step">
    <h2>Paso 7 – Regeneración de los ficheros de entrenamiento</h2>
    <p>
      Elimino y vuelvo a crear de>data</code> con de>train.jsonl</code> y de>valid.jsonl</code> 
      corregidos. Reviso el contenido con de>cat</code>.
    </p>
    <!-- GitHub File: WhatsApp Image 2026-02-06 at 16.28.39 (1).jpeg -->
    <img src="WhatsApp%20Image%202026-02-06%20at%2016.28.39%20(1).jpeg" alt="Regeneración de datos JSONL">
    <div class="caption">Nueva generación de los ficheros de datos con más ejemplos.</div>
  </section>

  <!-- Paso 8 -->
  <section class="step">
    <h2>Paso 8 – Carga del dataset: error de índice</h2>
    <p>
      Falla al cargar el dataset local con de>IndexError: list index out of range</code>, 
      posiblemente por formato incorrecto o lista vacía al leer los JSONL.
    </p>
    <!-- GitHub File: WhatsApp Image 2026-02-06 at 16.28.41.jpeg -->
    <img src="WhatsApp%20Image%202026-02-06%20at%2016.28.41.jpeg" alt="Error IndexError al cargar el dataset">
    <div class="caption">Fallo al leer el dataset local.</div>
  </section>

  <!-- Paso 9 -->
  <section class="step">
    <h2>Paso 9 – Ajuste del contenido de los JSONL</h2>
    <p>
      Edito nuevamente los archivos para asegurar el formato de mensajes. Relanzo el entrenamiento 
      pero aún requiere más datos de validación.
    </p>
    <!-- GitHub File: WhatsApp Image 2026-02-06 at 16.28.41 (1).jpeg -->
    <img src="WhatsApp%20Image%202026-02-06%20at%2016.28.41%20(1).jpeg" alt="Nuevo intento">
    <div class="caption">Relanzando el entrenamiento tras corregir los ficheros.</div>
  </section>

  <!-- Paso 10 -->
  <section class="step">
    <h2>Paso 10 – Ampliación definitiva de train y valid</h2>
    <p>
      Añado más ejemplos (bases de datos, comandos Linux) para cumplir la regla de 
      de>batch_size*2</code> en el conjunto de validación.
    </p>
    <!-- GitHub File: WhatsApp Image 2026-02-06 at 16.28.41 (2).jpeg -->
    <img src="WhatsApp%20Image%202026-02-06%20at%2016.28.41%20(2).jpeg" alt="Ampliación del dataset">
    <div class="caption">Ampliación del dataset para evitar errores en la evaluación.</div>
  </section>

  <!-- Paso 11 -->
  <section class="step">
    <h2>Paso 11 – Entrenamiento exitoso</h2>
    <p>
      Ejecuto de>mlx_lm_lora.train</code> con éxito. Se completan las 50 iteraciones 
      y se guardan los pesos en de>adapters.safetensors</code>.
    </p>
    <!-- GitHub File: WhatsApp Image 2026-02-06 at 16.28.40.jpeg -->
    <img src="WhatsApp%20Image%202026-02-06%20at%2016.28.40.jpeg" alt="Entrenamiento exitoso">
    <div class="caption">Entrenamiento completado y guardado de los adaptadores.</div>
  </section>

  <!-- Paso 12 -->
  <section class="step">
    <h2>Paso 12 – Modelos Gemma 3‑270M‑it MLX</h2>
    <p>
      Referencia de las variantes disponibles del modelo en la comunidad MLX.
    </p>
    <!-- GitHub File: WhatsApp Image 2026-02-06 at 16.28.39.jpeg -->
    <img src="WhatsApp%20Image%202026-02-06%20at%2016.28.39.jpeg" alt="Variantes Gemma MLX">
    <div class="caption">Variantes del modelo Gemma 3‑270M‑it.</div>
  </section>

  <!-- Miniatura -->
  <section class="step">
    <h2>Extra</h2>
    <p>Miniatura del proyecto.</p>
    <!-- GitHub File: WhatsApp Image 2026-02-06 at 16.28.41 (3).jpeg -->
    <img src="WhatsApp%20Image%202026-02-06%20at%2016.28.41%20(3).jpeg" alt="Miniatura">
  </section>

</body>
</html>


